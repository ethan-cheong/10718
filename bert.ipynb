{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71aa294e-e145-4d12-ae35-cfb141d4cdb6",
   "metadata": {},
   "source": [
    "# Prep data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e0f39d90-4d87-498c-b225-b005a1d58d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1adffae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df_classification(path_name:str):\n",
    "    df = pd.concat (\n",
    "    [pd.read_csv(os.path.join(path_name, \"train_cleaned.csv\"), index_col = [0]),\n",
    "    pd.read_csv(os.path.join(path_name, \"val_cleaned.csv\"), index_col = [0])], axis=0\n",
    "        )\n",
    "    df['len'] = df.statement.str.split().str.len()\n",
    "    labels = list(df['label'].unique())\n",
    "    vals = np.linspace(0, 1, 7)\n",
    "    label_to_val = {\n",
    "        \"pants-fire\": 0.0,\n",
    "        \"false\" : 1.0,\n",
    "        \"barely-true\": 2.0, \n",
    "        \"half-true\": 3.0, \n",
    "        \"mostly-true\" : 4.0, \n",
    "        \"true\" : 5.0,\n",
    "    }\n",
    "    df = df.query(\"len <= 100\") # drop everything longer than 100 tokens\n",
    "    df = df[['label', 'statement']]\n",
    "    df.label = df['label'].map(label_to_val)\n",
    "    return (df.statement.values, df.label.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "490c117b-b72c-4c39-8c15-5d70770b7b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(path_name:str):\n",
    "    df = pd.concat (\n",
    "    [pd.read_csv(os.path.join(path_name, \"train_cleaned.csv\"), index_col = [0]),\n",
    "    pd.read_csv(os.path.join(path_name, \"val_cleaned.csv\"), index_col = [0])], axis=0\n",
    "        )\n",
    "    df['len'] = df.statement.str.split().str.len()\n",
    "    labels = list(df['label'].unique())\n",
    "    vals = np.linspace(0, 1, 7)\n",
    "    label_to_val = {\n",
    "        \"pants-fire\": vals[0],\n",
    "        \"false\" : vals[1],\n",
    "        \"barely-true\": vals[2],\n",
    "        \"half-true\": vals[3],\n",
    "        \"mostly-true\" :vals[4],\n",
    "        \"true\" : vals[5]\n",
    "    }\n",
    "    df = df.query(\"len <= 100\") # drop everything longer than 100 tokens\n",
    "    df = df[['label', 'statement']]\n",
    "    df.label = df['label'].map(label_to_val)\n",
    "    return (df.statement.values, df.label.values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7f91cb73-a252-415a-93b0-ae1150824720",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, labels = process_df_classification(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5754e65-c168-47b5-8fce-3f2ea2af6ae9",
   "metadata": {},
   "source": [
    "# Tokenization and Input Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6bc9c1f4-73c6-4fe8-a07a-a8dd8a69130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e172daa5-af15-48e8-ae18-4b220c562273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethan/10718/.conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "37c28eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "\n",
    "for sent in sentences:\n",
    "  input_ids = tokenizer.encode(sent, add_special_tokens=True) # add required special tokens\n",
    "  max_len = max(max_len, len(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "de8722cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892ef636",
   "metadata": {},
   "source": [
    "Use `tokenizer.encode_plus` to split sentence into tokens, add [CLS] and [SEP] tokens, map tokens to Ids, pad or truncate sequences, and create attention masks which differentiate real tokens from [PAD] tokens. We only consider the first 100 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "842c2107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/Users/ethan/10718/.conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for sent in sentences:\n",
    "  encoded_dict = tokenizer.encode_plus(\n",
    "    sent, \n",
    "    add_special_tokens = True, \n",
    "    max_length = 100,\n",
    "    pad_to_max_length = True, \n",
    "    return_attention_mask = True,\n",
    "    return_tensors = 'pt'\n",
    "  )\n",
    "  input_ids.append(encoded_dict['input_ids'])\n",
    "  attention_masks.append(encoded_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d743b572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f5adea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779dce40",
   "metadata": {},
   "source": [
    "# Training and Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bd0b3cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59196ca5",
   "metadata": {},
   "source": [
    "Iterator using dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fe25db26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "  train_dataset,\n",
    "  sampler = RandomSampler(train_dataset),\n",
    "  batch_size = batch_size\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "  val_dataset,\n",
    "  sampler = SequentialSampler(val_dataset),\n",
    "  batch_size =batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "455d66ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do BERT for classificaiton first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "14a7537d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
    "num_labels = 6,\n",
    "output_attentions = False,\n",
    "output_hidden_states = False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4b31a1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethan/10718/.conda/lib/python3.11/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ef1fa618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4.\n",
    "epochs = 3\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs].\n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "37f872fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "266abc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3d080308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "92d34612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Batch     0 of   324.\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  total_loss = 0\n",
    "  all_predictions = []\n",
    "  all_labels = []\n",
    "\n",
    "  t0 = time.time()\n",
    "  for i, batch in enumerate(train_dataloader):\n",
    "      print( \" Batch {:>5,} of {:>5,}.\".format(i, len(train_dataloader)))\n",
    "      optimizer.zero_grad()\n",
    "      \n",
    "      b_input_ids = batch[0].to(device)\n",
    "      b_attention_mask = batch[1].to(device)\n",
    "      b_labels = batch[2].to(device)\n",
    "\n",
    "      outputs = model(input_ids=b_input_ids, attention_mask=b_attention_mask, labels=b_labels)\n",
    "      loss = outputs.loss\n",
    "      total_loss += loss.item()\n",
    "\n",
    "      # Get predictions\n",
    "      logits = outputs.logits\n",
    "      predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "      all_predictions.extend(predictions.cpu().numpy())\n",
    "      all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "      optimizer.step()\n",
    "\n",
    "  avg_loss = total_loss / len(dataloader)\n",
    "  print(f\"Training time took {format_time(time.time() - t0)}\")\n",
    "  print(f'Epoch {epoch + 1}, Loss: {avg_loss:.4f}')\n",
    "# Tracking variables\n",
    "  total_eval_accuracy = 0\n",
    "  total_eval_loss = 0\n",
    "  nb_eval_steps = 0\n",
    "\n",
    "  # Evaluate data for one epoch\n",
    "  for batch in validation_dataloader:\n",
    "\n",
    "      # Unpack this training batch from our dataloader.\n",
    "      #\n",
    "      # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
    "      # the `to` method.\n",
    "      #\n",
    "      # `batch` contains three pytorch tensors:\n",
    "      #   [0]: input ids\n",
    "      #   [1]: attention masks\n",
    "      #   [2]: labels\n",
    "      b_input_ids = batch[0].to(device)\n",
    "      b_input_mask = batch[1].to(device)\n",
    "      b_labels = batch[2].to(device)\n",
    "\n",
    "      # Tell pytorch not to bother with constructing the compute graph during\n",
    "      # the forward pass, since this is only needed for backprop (training).\n",
    "      with torch.no_grad():\n",
    "\n",
    "          # Forward pass, calculate logit predictions.\n",
    "          # token_type_ids is the same as the \"segment ids\", which\n",
    "          # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "          result = model(b_input_ids,\n",
    "                          token_type_ids=None,\n",
    "                          attention_mask=b_input_mask,\n",
    "                          labels=b_labels,\n",
    "                          return_dict=True)\n",
    "\n",
    "      # Get the loss and \"logits\" output by the model. The \"logits\" are the\n",
    "      # output values prior to applying an activation function like the\n",
    "      # softmax.\n",
    "      loss = result.loss\n",
    "      logits = result.logits\n",
    "\n",
    "      # Accumulate the validation loss.\n",
    "      total_eval_loss += loss.item()\n",
    "\n",
    "      # Move logits and labels to CPU\n",
    "      logits = logits.detach().cpu().numpy()\n",
    "      label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "      # Calculate the accuracy for this batch of test sentences, and\n",
    "      # accumulate it over all batches.\n",
    "      total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "    # Report the final accuracy for this validation run.\n",
    "  avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "  print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b548fe97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
