{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27a776bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a2d4f6c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nColumn 1: the ID of the statement ([ID].json).\\nColumn 2: the label.\\nColumn 3: the statement.\\nColumn 4: the subject(s).\\nColumn 5: the speaker.\\nColumn 6: the speaker's job title.\\nColumn 7: the state info.\\nColumn 8: the party affiliation.\\nColumn 9-13: the total credit history count, including the current statement.\\n9: barely true counts.\\n10: false counts.\\n11: half true counts.\\n12: mostly true counts.\\n13: pants on fire counts.\\nColumn 14: the context (venue / location of the speech or statement).\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column info\n",
    "# data from https://www.kaggle.com/datasets/doanquanvietnamca/liar-dataset?resource=download\n",
    "'''\n",
    "Column 1: the ID of the statement ([ID].json).\n",
    "Column 2: the label.\n",
    "Column 3: the statement.\n",
    "Column 4: the subject(s).\n",
    "Column 5: the speaker.\n",
    "Column 6: the speaker's job title.\n",
    "Column 7: the state info.\n",
    "Column 8: the party affiliation.\n",
    "Column 9-13: the total credit history count, including the current statement.\n",
    "9: barely true counts.\n",
    "10: false counts.\n",
    "11: half true counts.\n",
    "12: mostly true counts.\n",
    "13: pants on fire counts.\n",
    "Column 14: the context (venue / location of the speech or statement).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afa6ef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_cleaned.csv\").drop(\"Unnamed: 0\",axis=1)\n",
    "test = pd.read_csv(\"test_cleaned.csv\").drop(\"Unnamed: 0\",axis=1)\n",
    "val = pd.read_csv(\"val_cleaned.csv\").drop(\"Unnamed: 0\",axis=1)\n",
    "all_data = pd.concat([train, test, val], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10d2dca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows where statement < 3 words\n",
    "def remove_short_and_long_statements(df):\n",
    "    df[\"len\"] = df[\"statement\"].str.split().str.len()\n",
    "    df = df[df[\"len\"] >= 3]\n",
    "    df = df[df[\"len\"] <= 100]\n",
    "    df = df.drop(\"len\", axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "016c628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = remove_short_and_long_statements(train)\n",
    "test = remove_short_and_long_statements(test)\n",
    "val = remove_short_and_long_statements(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860c6774",
   "metadata": {},
   "source": [
    "# Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95172590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_text_features(df):\n",
    "    new_statements = [ ]\n",
    "    for index, row in df.iterrows():\n",
    "        speaker = \" \".join(row[\"speaker\"].split(\"-\"))\n",
    "        new_text = f'I am {speaker}, a {row[\"speaker_job\"]} and a {row[\"party\"]} from {row[\"state\"]}. I am at {row[\"context\"]}. '\n",
    "        new_statements.append(new_text + row[\"statement\"])\n",
    "    \n",
    "    df[\"statement\"] = new_statements\n",
    "    \n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "608a4225",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_text_features(train)\n",
    "test = add_text_features(test)\n",
    "val = add_text_features(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e160543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "# from official.nlp import optimization  # to create AdamW optimizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e0aefbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee195dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_val = {\n",
    "        \"pants-fire\": 0,\n",
    "        \"false\" : 1,\n",
    "        \"barely-true\": 2,\n",
    "        \"half-true\": 3,\n",
    "        \"mostly-true\": 4,\n",
    "        \"true\" : 5\n",
    "}\n",
    "train[\"label\"] = train['label'].map(label_to_val)\n",
    "test[\"label\"] = test['label'].map(label_to_val)\n",
    "val[\"label\"] = val['label'].map(label_to_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a3a79bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load data\n",
    "num_classes = len(train[\"label\"].unique())\n",
    "\n",
    "# train data\n",
    "train = train[[\"statement\", \"label\"]]\n",
    "x_train = train[\"statement\"]\n",
    "y_train = tf.keras.utils.to_categorical(train[\"label\"].values, num_classes=num_classes)\n",
    "\n",
    "# test data\n",
    "test = test[[\"statement\", \"label\"]]\n",
    "x_test = test[\"statement\"]\n",
    "y_test = tf.keras.utils.to_categorical(test[\"label\"].values, num_classes=num_classes)\n",
    "\n",
    "# validation data\n",
    "val = val[[\"statement\", \"label\"]]\n",
    "x_val = val[\"statement\"]\n",
    "y_val = tf.keras.utils.to_categorical(val[\"label\"].values, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6852fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8' \n",
    "# bert_model_name = 'small_bert/bert_en_uncased_L-12_H-128_A-2'\n",
    "\n",
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44b1b20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 13:57:49.090295: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "preprocessor = hub.KerasLayer(tfhub_handle_preprocess)\n",
    "encoder = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43340225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(sentences):\n",
    "    '''return BERT-like embeddings of input text\n",
    "    Args:\n",
    "     - sentences: list of strings\n",
    "    Output:\n",
    "      - BERT-like embeddings: tf.Tensor of shape=(len(sentences), 768)\n",
    "    '''\n",
    "    preprocessed_text = preprocessor(sentences)\n",
    "    return encoder(preprocessed_text)['pooled_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a60e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a model as the preprocessor and encoder layers followed by a dropout and a dense layer with a \n",
    "# softmax activation function and an output space dimensionality equal to the number of classes we want to predict\n",
    "num_classes = 6\n",
    "i = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "x = preprocessor(i)\n",
    "x = encoder(x)\n",
    "x = tf.keras.layers.Dropout(0.1, name=\"dropout\")(x['pooled_output']) # 0.2\n",
    "x = tf.keras.layers.Dense(num_classes, activation='softmax', name=\"output\")(x)\n",
    "\n",
    "model = tf.keras.Model(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b935902f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "320/320 [==============================] - 390s 1s/step - loss: 1.8043 - accuracy: 0.2135 - cross_entropy: 1.8043 - val_loss: 1.7212 - val_accuracy: 0.2296 - val_cross_entropy: 1.7212\n",
      "Epoch 2/20\n",
      "320/320 [==============================] - 337s 1s/step - loss: 1.7575 - accuracy: 0.2296 - cross_entropy: 1.7575 - val_loss: 1.7213 - val_accuracy: 0.2280 - val_cross_entropy: 1.7213\n",
      "Epoch 3/20\n",
      "320/320 [==============================] - 364s 1s/step - loss: 1.7434 - accuracy: 0.2394 - cross_entropy: 1.7434 - val_loss: 1.6921 - val_accuracy: 0.2565 - val_cross_entropy: 1.6921\n",
      "Epoch 4/20\n",
      "320/320 [==============================] - 360s 1s/step - loss: 1.7356 - accuracy: 0.2452 - cross_entropy: 1.7356 - val_loss: 1.7130 - val_accuracy: 0.2288 - val_cross_entropy: 1.7130\n",
      "Epoch 5/20\n",
      "320/320 [==============================] - 333s 1s/step - loss: 1.7227 - accuracy: 0.2521 - cross_entropy: 1.7227 - val_loss: 1.7011 - val_accuracy: 0.2367 - val_cross_entropy: 1.7011\n",
      "Epoch 6/20\n",
      "320/320 [==============================] - 332s 1s/step - loss: 1.7163 - accuracy: 0.2502 - cross_entropy: 1.7163 - val_loss: 1.6967 - val_accuracy: 0.2447 - val_cross_entropy: 1.6967\n"
     ]
    }
   ],
   "source": [
    "# compile and fit model\n",
    "# if the metric does not improve for at least 3 epochs (patience), the training is interrupted and the weights \n",
    "# from the epoch where the validation loss showed the best value (i.e. lowest) are restored\n",
    "n_epochs = 20\n",
    "\n",
    "METRICS = [\n",
    "      tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"), \n",
    "      tf.keras.metrics.CategoricalCrossentropy(name=\"cross_entropy\")\n",
    "]\n",
    "\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", \n",
    "                                                      patience = 3,\n",
    "                                                      restore_best_weights = True)\n",
    "\n",
    "model.compile(optimizer = \"adam\",\n",
    "              loss = \"categorical_crossentropy\",\n",
    "              metrics = METRICS)\n",
    "\n",
    "model_fit = model.fit(x_train, \n",
    "                      y_train, \n",
    "                      epochs = n_epochs,\n",
    "                      validation_data = (x_test, y_test),\n",
    "                      callbacks = [earlystop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f09aefe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model on validation set\n",
    "def predict_class(statements):\n",
    "    '''predict class of input text\n",
    "    '''\n",
    "    return [np.argmax(pred) for pred in model.predict(statements)]\n",
    "\n",
    "# predict_class(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88ed50a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.17      0.26       116\n",
      "           1       0.23      0.32      0.27       263\n",
      "           2       0.21      0.19      0.20       237\n",
      "           3       0.21      0.28      0.24       248\n",
      "           4       0.31      0.29      0.30       251\n",
      "           5       0.22      0.14      0.17       169\n",
      "\n",
      "    accuracy                           0.24      1284\n",
      "   macro avg       0.29      0.23      0.24      1284\n",
      "weighted avg       0.27      0.24      0.24      1284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test set performance\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = predict_class(val[\"statement\"])\n",
    "print(classification_report(val[\"label\"], y_pred))\n",
    "\n",
    "print(\"MAE\", mae(y_pred, val[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "870740f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(pred, actual):\n",
    "    return np.sum(np.abs(pred - actual)) / len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "787e9517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3714953271028036"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae(y_pred, val[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3753fe80",
   "metadata": {},
   "source": [
    "# Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ed1a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_cleaned.csv\").drop(\"Unnamed: 0\",axis=1)\n",
    "test = pd.read_csv(\"test_cleaned.csv\").drop(\"Unnamed: 0\",axis=1)\n",
    "val = pd.read_csv(\"val_cleaned.csv\").drop(\"Unnamed: 0\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca53b19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = remove_short_and_long_statements(train)\n",
    "test = remove_short_and_long_statements(test)\n",
    "val = remove_short_and_long_statements(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4dcd0816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_num_features(df):\n",
    "    new_statements = [ ]\n",
    "    for index, row in df.iterrows():\n",
    "        speaker = \" \".join(row[\"speaker\"].split(\"-\"))\n",
    "        new_text = f'I am {speaker}, a {row[\"speaker_job\"]} and a {row[\"party\"]} from {row[\"state\"]}. I am at {row[\"context\"]}. I have said {int(row[\"barely_true_counts\"])} barely true statements, {int(row[\"false_counts\"])} statements, {int(row[\"half_true_counts\"])} half true statements, {int(row[\"mostly_true_counts\"])} mostly true statements, and {int(row[\"pants_on_fire_counts\"])} completely false statements. '\n",
    "        new_statements.append(new_text + row[\"statement\"])\n",
    "    df[\"statement\"] = new_statements\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b40b74c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_num_features(train)\n",
    "test = add_num_features(test)\n",
    "val = add_num_features(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "948d90e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_val = {\n",
    "        \"pants-fire\": 0,\n",
    "        \"false\" : 1,\n",
    "        \"barely-true\": 2,\n",
    "        \"half-true\": 3,\n",
    "        \"mostly-true\": 4,\n",
    "        \"true\" : 5\n",
    "}\n",
    "train[\"label\"] = train['label'].map(label_to_val)\n",
    "test[\"label\"] = test['label'].map(label_to_val)\n",
    "val[\"label\"] = val['label'].map(label_to_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3e7e101",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = hub.KerasLayer(tfhub_handle_preprocess)\n",
    "encoder = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e30351de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a model as the preprocessor and encoder layers followed by a dropout and a dense layer with a \n",
    "# softmax activation function and an output space dimensionality equal to the number of classes we want to predict\n",
    "num_classes = 6\n",
    "i = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "x = preprocessor(i)\n",
    "x = encoder(x)\n",
    "x = tf.keras.layers.Dropout(0.2, name=\"dropout\")(x['pooled_output']) # 0.2\n",
    "x = tf.keras.layers.Dense(num_classes, activation='softmax', name=\"output\")(x)\n",
    "\n",
    "model = tf.keras.Model(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "536989f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "320/320 [==============================] - 346s 1s/step - loss: 1.8566 - accuracy: 0.1985 - cross_entropy: 1.8566 - val_loss: 1.7285 - val_accuracy: 0.2304 - val_cross_entropy: 1.7285\n",
      "Epoch 2/20\n",
      "320/320 [==============================] - 310s 968ms/step - loss: 1.7815 - accuracy: 0.2273 - cross_entropy: 1.7815 - val_loss: 1.7085 - val_accuracy: 0.2415 - val_cross_entropy: 1.7085\n",
      "Epoch 3/20\n",
      "320/320 [==============================] - 316s 988ms/step - loss: 1.7540 - accuracy: 0.2357 - cross_entropy: 1.7540 - val_loss: 1.7072 - val_accuracy: 0.2399 - val_cross_entropy: 1.7072\n",
      "Epoch 4/20\n",
      "320/320 [==============================] - 309s 964ms/step - loss: 1.7457 - accuracy: 0.2465 - cross_entropy: 1.7457 - val_loss: 1.7097 - val_accuracy: 0.2391 - val_cross_entropy: 1.7097\n",
      "Epoch 5/20\n",
      "320/320 [==============================] - 312s 975ms/step - loss: 1.7410 - accuracy: 0.2462 - cross_entropy: 1.7410 - val_loss: 1.6957 - val_accuracy: 0.2605 - val_cross_entropy: 1.6957\n",
      "Epoch 6/20\n",
      "320/320 [==============================] - 310s 971ms/step - loss: 1.7336 - accuracy: 0.2424 - cross_entropy: 1.7336 - val_loss: 1.7006 - val_accuracy: 0.2542 - val_cross_entropy: 1.7006\n",
      "Epoch 7/20\n",
      "320/320 [==============================] - 328s 1s/step - loss: 1.7166 - accuracy: 0.2510 - cross_entropy: 1.7166 - val_loss: 1.6992 - val_accuracy: 0.2502 - val_cross_entropy: 1.6992\n",
      "Epoch 8/20\n",
      "320/320 [==============================] - 346s 1s/step - loss: 1.7081 - accuracy: 0.2631 - cross_entropy: 1.7081 - val_loss: 1.6988 - val_accuracy: 0.2526 - val_cross_entropy: 1.6988\n"
     ]
    }
   ],
   "source": [
    "# compile and fit model\n",
    "# if the metric does not improve for at least 3 epochs (patience), the training is interrupted and the weights \n",
    "# from the epoch where the validation loss showed the best value (i.e. lowest) are restored\n",
    "n_epochs = 20\n",
    "\n",
    "METRICS = [\n",
    "      tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"), \n",
    "      tf.keras.metrics.CategoricalCrossentropy(name=\"cross_entropy\")\n",
    "]\n",
    "\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", \n",
    "                                                      patience = 3,\n",
    "                                                      restore_best_weights = True)\n",
    "\n",
    "model.compile(optimizer = \"adam\",\n",
    "              loss = \"categorical_crossentropy\",\n",
    "              metrics = METRICS)\n",
    "\n",
    "model_fit = model.fit(x_train, \n",
    "                      y_train, \n",
    "                      epochs = n_epochs,\n",
    "                      validation_data = (x_test, y_test),\n",
    "                      callbacks = [earlystop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee8e3966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.23      0.28       116\n",
      "           1       0.25      0.15      0.19       263\n",
      "           2       0.16      0.03      0.06       237\n",
      "           3       0.22      0.53      0.31       248\n",
      "           4       0.28      0.31      0.30       251\n",
      "           5       0.20      0.15      0.17       169\n",
      "\n",
      "    accuracy                           0.24      1284\n",
      "   macro avg       0.24      0.24      0.22      1284\n",
      "weighted avg       0.24      0.24      0.22      1284\n",
      "\n",
      "MAE 1.3870716510903427\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_class(val[\"statement\"])\n",
    "print(classification_report(val[\"label\"], y_pred))\n",
    "\n",
    "print(\"MAE\", mae(y_pred, val[\"label\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0159629f",
   "metadata": {},
   "source": [
    "# Method 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "64c47f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_cleaned.csv\").drop(\"Unnamed: 0\",axis=1)\n",
    "test = pd.read_csv(\"test_cleaned.csv\").drop(\"Unnamed: 0\",axis=1)\n",
    "val = pd.read_csv(\"val_cleaned.csv\").drop(\"Unnamed: 0\",axis=1)\n",
    "all_data = pd.concat([train, test, val], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "4265dc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = remove_short_and_long_statements(train)\n",
    "test = remove_short_and_long_statements(test)\n",
    "val = remove_short_and_long_statements(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "8e0d9d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_text_features(train)\n",
    "test = add_text_features(test)\n",
    "val = add_text_features(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d84051ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d756bd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'  # You can choose other BERT models\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb36d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode_plus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "98e962bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(texts: list[str], batch_size: int =10) -> torch.tensor:\n",
    "  \"\"\"Returns mean vector for the last hidden layer from the Bert Model\n",
    "\n",
    "  Args:\n",
    "    texts: (list[str]) - List of sentences/paragraph\n",
    "    batch_size: int - Number of sentences in a single batch\n",
    "\n",
    "  Returns:\n",
    "    torch.tensor -- embedding for each sentence/paragraph in texts\n",
    "  \"\"\"\n",
    "  torch.cuda.empty_cache()\n",
    "\n",
    "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "  model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "  # determine number of buckets\n",
    "  num_buckets = math.ceil(len(texts) // batch_size)\n",
    "\n",
    "  # split data into buckets and generate embeddings\n",
    "  vectors = []\n",
    "  for bucket in np.array_split(texts, num_buckets):\n",
    "    model = model.to('cuda') # Move the model to GPU\n",
    "    with torch.no_grad():\n",
    "      tokens = tokenizer(bucket.tolist(), return_tensors=\"pt\", padding=True, truncation=True).to('cuda')\n",
    "      embeddings = model(**tokens).last_hidden_state.mean(dim=1).detach().cpu()\n",
    "      model = model.cpu()\n",
    "    vectors.append(embeddings)\n",
    "\n",
    "  return torch.concatenate(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547411ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_features(df, embeddings):\n",
    "  num_cols = [\"barely_true_counts\", \"false_counts\", \"half_true_counts\", \"mostly_true_counts\",\n",
    "              \"pants_on_fire_counts\"]\n",
    "  num_features = torch.tensor(df[num_cols].astype(\"float32\").values)\n",
    "\n",
    "  return torch.cat((embeddings, num_features), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e2eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bert = get_embeddings(train[\"statement\"].to_list())\n",
    "test_bert = get_embeddings(test[\"statement\"].to_list())\n",
    "val_bert = get_embeddings(val[\"statement\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7787af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = get_num_features(train, train_bert)\n",
    "test_x = get_num_features(test, test_bert)\n",
    "val_x = get_num_features(val, val_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24360aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_val = {\n",
    "        \"pants-fire\": 0,\n",
    "        \"false\" : 1,\n",
    "        \"barely-true\": 2,\n",
    "        \"half-true\": 3,\n",
    "        \"mostly-true\": 4,\n",
    "        \"true\" : 5\n",
    "}\n",
    "train[\"label\"] = train['label'].map(label_to_val)\n",
    "test[\"label\"] = test['label'].map(label_to_val)\n",
    "val[\"label\"] = val['label'].map(label_to_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd09a970",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = torch.tensor(train[\"label\"].to_numpy())\n",
    "test_y = torch.tensor(test[\"label\"].to_numpy())\n",
    "val_y = torch.tensor(val[\"label\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40951e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainloaders(train, test, val, batch_size = 32):\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "                train,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "    )\n",
    "    val_dataloader = torch.utils.data.DataLoader(\n",
    "                val,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "    )\n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "                test,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "    )\n",
    "\n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d94b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = torch.reshape(y, (y.shape[0], 1))\n",
    "\n",
    "    def __len__(self):\n",
    "        # number of samples\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __numfeatures__(self):\n",
    "        # number of features/columns\n",
    "        return self.X.shape[1]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # returns sample at index\n",
    "        return self.X[index].float(), self.y[index].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72164893",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Data(train_x, train_y)\n",
    "test_dataset = Data(test_x, test_y)\n",
    "val_dataset = Data(val_x, val_y)\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = get_trainloaders(train, test, val, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd325f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964634af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulticlassModel(nn.Module):\n",
    "  def __init__(self, input_size, num_classes):\n",
    "    super().__init__()\n",
    "\n",
    "    self.X_size = input_size\n",
    "    self.layers = nn.Sequential(\n",
    "              nn.Linear(input_size, 64),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(64, 32),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(32, num_classes)\n",
    "            )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fba30e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size = train_x.shape[1]\n",
    "num_classes = 6\n",
    "model = MulticlassModel(input_size, num_classes).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba90385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "# torch.manual_seed(42)\n",
    "\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc\n",
    "\n",
    "epochs = 400\n",
    "\n",
    "train_x, train_y = train_x.to(device), train_y.to(device)\n",
    "val_x, val_y = val_x.to(device), val_y.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    # 1. Forward pass\n",
    "    y_logits = model(train_x) # model outputs raw logits\n",
    "    y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1) # go from logits -> prediction probabilities -> prediction labels\n",
    "\n",
    "    # 2. Calculate loss and accuracy\n",
    "    loss = loss_fn(y_logits, train_y)\n",
    "    acc = accuracy_fn(y_true=train_y,\n",
    "                      y_pred=y_pred)\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "      # 1. Forward pass\n",
    "      test_logits = model(val_x)\n",
    "      test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
    "      # 2. Calculate test loss and accuracy\n",
    "      test_loss = loss_fn(test_logits, val_y)\n",
    "      test_acc = accuracy_fn(y_true=val_y,\n",
    "                             y_pred=test_pred)\n",
    "\n",
    "    # Print out what's happening\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Acc: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Acc: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fcacaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "test_x, test_y = test_x.to(device), test_y.to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    y_logits = model(test_x)\n",
    "\n",
    "y_pred_probs = torch.softmax(y_logits, dim=1)\n",
    "\n",
    "# Turn prediction probabilities into prediction labels\n",
    "y_preds = y_pred_probs.argmax(dim=1)\n",
    "\n",
    "# Compare first 10 model preds and test labels\n",
    "print(f\"Predictions: {y_preds[:10]}\\nLabels: {test_y[:10]}\")\n",
    "print(f\"Test accuracy: {accuracy_fn(y_true=test_y, y_pred=y_preds)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36110833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(pred, actual):\n",
    "    return np.abs(pred.cpu() - actual.cpu()).sum().item() / len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf632f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae(y_preds, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
